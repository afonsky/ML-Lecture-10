# Support Vector Machines: Motivation

<div>
<v-plotly style="height: 400px; position: relative"
:data="[{
x: [
    0.211730045019069,
    0.1399601922173722,
    0.09100734571954973,
    0.04565186599013943,
    0.02229411175382152,
    -0.4020241010954035,
    -0.05127642386368402,
    0.11601809319272058,
    -0.07596922046323512,
    0.16465468612120826,
    -0.0870423854042889,
    -0.08997129142680872,
    0.012619316105465784,
    -0.08855509689415027,
    0.11581367152912996,
    -0.003647807389358088,
    0.009556065521930225,
    0.075641348862595,
    0.2013758987498504,
    -0.046680759918900874,
    0.18223444634883154,
    0.058540981168432135,
    -0.007950681436436926,
    -0.19549025528569147,
    -0.05174899244098759,
    -0.12120917533771787,
    -0.11363739353228147,
    -0.34825727907583554,
    -0.04977211734158469,
    -0.16998198852340005
  ],
y: [
    0.026981175072152336,
    0.07786569741310974,
    0.12836363998580316,
    0.06930079970867901,
    0.13850133057154207,
    0.0516338174025865,
    -0.024252161044720544,
    0.13282627951397288,
    -0.0362942786558502,
    0.015875815877918704,
    0.30096894026200954,
    -0.04326671482071785,
    -0.04849214722942504,
    0.030724858590092975,
    -0.2956460790399235,
    0.18688960431532295,
    -0.21415636171832217,
    -0.10888304417318244,
    -0.09350913206510617,
    -0.12995358968632717,
    0.22420249707896076,
    -0.2396996877056416,
    -0.03453763654870824,
    0.01917876868638081,
    -0.06924188939499257,
    0.21792230720230202,
    0.012497743953121128,
    0.00044028677685690353,
    -0.19278404740869112,
    0.21988564679347367
  ],
z: [
    1.2071773660254017,
    0.9154773105607806,
    1.2828326555121705,
    0.9907651763442729,
    1.1718223489342445,
    0.903707797243288,
    0.9800786676538313,
    0.9095393596177689,
    0.9262002952750491,
    0.931563019523599,
    1.2817313402725712,
    0.6907751973438815,
    1.044868422848409,
    1.067914470766121,
    1.1384087586772729,
    1.1554858572346578,
    0.7622024761525107,
    0.9850509134768108,
    0.9944447763470097,
    0.8132323825274675,
    0.9566794149098861,
    1.1681831407412786,
    0.9366523262090453,
    1.0345102266771824,
    0.9944427292517971,
    1.0977457888409077,
    1.0318080984695273,
    1.1132006348499828,
    1.155906735862401,
    0.9872697499700506
  ],
type: 'scatter3d',
mode: 'markers',
marker: {color: 'red', size: 4, opacity: 0.5},
showlegend: false
},
{
x: [
    -0.1762815399320112,
    -0.2775478617745998,
    0.4065759076560167,
    -0.33244945022559663,
    -0.18780633815518985,
    -0.12782060781444926,
    -0.5906202702564949,
    0.6111520364398563,
    0.39361707810614405,
    0.042477547092632545,
    -0.5749230480699967,
    0.9203647833483696,
    -0.7288644188561423,
    0.423834066164925,
    0.21449268003148825,
    -0.05210551285390154,
    0.3921651913422808,
    0.9615281327629841,
    -0.19650819778608217,
    0.18011955056045315,
    -1.1590632906094105,
    0.506015517299937,
    -1.3620465851353367,
    -0.1468588767607886,
    -1.0765705277429762,
    0.8709304940505754,
    -0.6930960032425925,
    0.33196410171495866,
    0.39443644438091746,
    -0.2369005192537579,
    0.1624817897555457,
    -1.3264110062518284,
    0.6431891872688725,
    0.9446403940424373,
    0.21494973605030904,
    0.37746035857782606,
    0.7220136826438909,
    1.206359694701605,
    -0.6721721084592864,
    -0.2594529017196629,
    -0.6209656479709096,
    -0.680078961195011,
    -0.7191634286684974,
    0.45447980677418354,
    0.07018330420342092,
    -0.610664920910668,
    -0.5892647355865684,
    0.7588311806999447,
    -0.8197843752054805,
    1.2155036193443525,
    -0.8098272208467739,
    -1.0021552533612428,
    -1.2732661125599707,
    -0.1371868382359825,
    -0.5244655554711066,
    0.8655881804224456,
    0.9696424185955933,
    -0.5442387960672836,
    0.009737171260468667,
    0.22692230249058937,
    0.41925003638807673,
    0.1798701337723241,
    0.5737210391548371,
    0.7089636616900225,
    -0.8300439641984582,
    0.5309725588301406,
    -0.11842181110100498,
    -0.17099139812449216,
    0.13964332305268148,
    0.8964681643127892,
    1.470147364987771,
    -0.2665731660261331,
    -0.5163874532364954,
    1.1812284567770845,
    -0.6301117793503727,
    1.5296858870642254,
    1.3303168468192736,
    0.20360989899475257,
    -0.011125897361967604,
    -0.6623065895591065,
    1.428340982825374,
    -1.1396823307026958,
    -0.6197957457930122,
    -0.5557323600238632,
    0.6220439160579856,
    0.9686328758012914,
    0.27218273620439554,
    -0.6360365834301717,
    -0.08008632361234361,
    0.6239121757357434,
    -1.2927826753308422,
    0.1858039009810382,
    0.43634862930535984,
    0.7112585890414014,
    0.7729232232465386,
    -0.0368479149777247,
    1.0273761995097996,
    0.9193408642989916,
    -0.7973561107410221,
    -0.7594719856007519,
    0.0368685577713413,
    -1.2565100305763588,
    -1.3424967338021503,
    0.38186494588900616,
    -0.5385533623373481,
    0.9707916941725995,
    -0.6732716102924374,
    0.45032952456484265,
    -0.8990586326485193,
    -1.2537982817174371,
    -0.3618205145617593,
    0.37182532191535117,
    -0.05901466652068775,
    -0.2726778820012787,
    -0.7314982086370175,
    0.043252592016653796,
    0.3966277084362583,
    -0.9804754462931201,
    1.2419098765505254,
    -0.5254296321835694,
    -0.5770813414777661,
    0.966828239264465,
    -0.8189417703490462,
    -0.14915307824850638,
    -0.37654526452784887,
    1.2368149155423167,
    0.033827281311329574,
    -0.33023637975764386,
    -1.1904108051658335,
    -1.1480808278827983,
    0.28260106177081656,
    -0.7438128088861977,
    -0.4763529892450295,
    0.8241347710202802,
    -0.36289603121005665,
    0.6323869168978825,
    1.0291671876727815,
    0.6279899494112309,
    -0.5381614623968052,
    0.7665459310611433,
    -0.7238041758823545,
    0.6866192635300794,
    -0.8992694246571541,
    -0.9622007915099624,
    -0.8145067746194318,
    1.163650754091398,
    -1.2437103977002029,
    -0.6491024648091804,
    -0.1994596974838446,
    0.7072965182064835,
    -0.14393522751025284,
    -0.1521118032488716,
    -0.14597215384725457,
    -0.048061461409012615,
    0.132668115838299,
    -0.08852040926691411,
    -0.11623253674577685,
    0.18781485843416587
  ],
y: [
    1.0166838658034847,
    1.390519712285972,
    0.5923332450121523,
    1.1284682862739317,
    1.2967575905202895,
    -0.4786166420794388,
    -0.9419204514941176,
    -1.3300998040036114,
    -0.48754394811084106,
    -0.9736652140756604,
    0.30117727883432677,
    -0.07671057591978253,
    -0.42577926292359136,
    -0.5146054797017569,
    -0.8934527882543494,
    1.365796176398344,
    0.7591915053456528,
    0.34475366208655833,
    1.4440831006230823,
    -1.0241353010991747,
    0.3444053800218606,
    0.10012387949852686,
    -0.43256579590754796,
    1.482658668546536,
    0.8679336528545722,
    0.8397473564276845,
    0.48785301614914406,
    0.4245122315600966,
    0.3686850669072826,
    1.2395684344923075,
    -0.7095600191473096,
    0.32285594694515096,
    -0.45049299938199894,
    1.0021935097286365,
    -0.9473894766642473,
    -0.41843988938624743,
    0.7718852038071395,
    -0.7845895426460792,
    -0.48590849350840987,
    -0.8491155934023155,
    0.8417646070965825,
    -0.0028165832133197405,
    -0.6033580418672836,
    -0.2473990620568035,
    1.3818680104188246,
    0.193236656339629,
    1.2623832817953649,
    0.6190986512457027,
    -1.0808193889057207,
    -0.6115024271949595,
    0.9776257198282007,
    -0.17598117477840228,
    -0.04122891027833539,
    -0.9093817099030445,
    -0.11067417760826227,
    0.3147109401937274,
    -0.4880910230934287,
    0.8811748477170195,
    -0.8531016850443311,
    1.0324752754608864,
    0.6630584029091053,
    -0.5387028336594263,
    0.2999129599496579,
    1.1190542235586687,
    -0.5854828607127468,
    -0.3952609249882547,
    -0.5297305008093659,
    -0.6668121715622405,
    -1.3354230409020331,
    -0.13458249064378952,
    0.32073042366511045,
    0.7908686830067925,
    0.9697408757677735,
    0.44045484064151763,
    0.010941383246869945,
    0.044250745411053845,
    0.6324472895923637,
    -0.7034046250290479,
    -0.8557739553329339,
    -0.34044823967878857,
    -0.2298808949142821,
    0.0774989023756028,
    -0.17001888489163527,
    0.867571582888856,
    0.6478516991007663,
    0.4262389851528269,
    -0.6549218094925546,
    0.8736826090412021,
    -0.5408787362785025,
    0.5996954579492736,
    -0.5856267184749369,
    1.0796914191959137,
    0.6747946658597201,
    -0.9094992116198526,
    0.18407555812147625,
    0.4913166982691653,
    -0.3059475237472725,
    1.1849315972256025,
    -0.1985249827478269,
    0.7212905248949979,
    -1.5204741826547192,
    0.2540236107785741,
    -0.32018535586686697,
    0.6884918825814255,
    0.9087662165231506,
    -0.12219408265092022,
    -0.9664296481914462,
    -1.0599917775544,
    -1.1137974758383136,
    0.40217908146037135,
    -0.4691200100883799,
    0.8516069832919579,
    -1.457296740435148,
    0.534427230726257,
    0.6593174245080619,
    -1.2352644925334675,
    -0.4568133420811782,
    -0.8506993449980194,
    -0.6093809050252084,
    -1.2776732864623164,
    0.8553512582694758,
    0.45434932192340055,
    0.3220131224638254,
    -1.033551664623954,
    -0.8217509826584531,
    0.17164954773377705,
    1.2418475679523806,
    1.31035004059439,
    -0.18891545452975755,
    0.4969151109284775,
    -1.1012774073095695,
    0.34883810653681097,
    -0.6304503203757748,
    -0.2286062684932462,
    -0.7251079677107489,
    -0.6984911058462873,
    -0.33273912666001065,
    -1.0159303873030365,
    -0.5522191842056581,
    -0.563300642202051,
    0.03977004367531557,
    -0.10007618584833419,
    -0.2475996148889859,
    -0.18219300645913905,
    -0.006454667336968485,
    -0.30030650437888684,
    0.5190503910303872,
    0.7705116653857029,
    0.5248552359610413,
    -0.3237801874746511,
    0.043883748933303955,
    -0.18065403844272998,
    0.18171205966148732,
    -0.247541532283507,
    -0.05426764161999166,
    0.26830125124516574,
    0.3544149895773857,
    -0.3050415959534765
  ],
z: [
    -1.0524754877043154,
    -1.021203553896458,
    -0.9474554789918119,
    -1.0361222859335564,
    -1.1229530915980541,
    -0.8367778216627968,
    -0.8655944238423168,
    -0.9554983644313657,
    -0.9956792443630851,
    -0.8869616894146151,
    -0.8953446708424903,
    -1.1872600202476238,
    -0.9160549551906002,
    -0.8580924415481685,
    -1.01590621226385,
    -1.0165313403688223,
    -0.9673958773062485,
    -1.05279165266448,
    -0.9527781590148965,
    -0.9859722821050054,
    -0.9638716495256379,
    -1.0571204698915333,
    -1.2109985704850486,
    -1.014466837983487,
    -1.0146161377943061,
    -0.9179834239657809,
    -0.9326174916775685,
    -1.0292673975695221,
    -0.8339591036506493,
    -0.8661750680009814,
    -1.0599633298359228,
    -0.9476744940371081,
    -0.9200148549013307,
    -1.1385107283079259,
    -0.8373239764266671,
    -1.1791867745076021,
    -1.102551952922109,
    -1.0441715093446544,
    -1.1681893640982226,
    -1.141817968072763,
    -1.0912465798652304,
    -0.9199922050759225,
    -1.1754325926942175,
    -0.9092396671923283,
    -1.0933763258437232,
    -0.9485053969794229,
    -1.1531130593475976,
    -0.9234171690077457,
    -0.9808182011932874,
    -1.1406728407724238,
    -1.1423242955584976,
    -1.1363190476271152,
    -1.0483495218540246,
    -1.032531475910219,
    -1.088292651908053,
    -1.0502449661657833,
    -1.019540573991881,
    -1.161033341037022,
    -1.0552683891676204,
    -1.1734439242643777,
    -0.9787265610952224,
    -1.075184958329237,
    -1.0202167397145523,
    -0.9482552988910765,
    -0.9584920831696104,
    -0.883358318961325,
    -0.9288886093348643,
    -0.9769901684946453,
    -0.9754531526824498,
    -1.142834386745037,
    -1.0417730468468689,
    -1.0540577627349623,
    -0.9251345830754037,
    -0.9986368586974886,
    -1.1275799767202086,
    -0.8660937819287939,
    -0.8199507891241582,
    -0.7437476329892766,
    -0.9393777071906607,
    -0.9543477054594198,
    -1.1564870034323484,
    -0.9090415858917202,
    -0.9984370339755713,
    -0.7947949625139932,
    -0.9503678732085251,
    -0.883412796098623,
    -1.1054709725926308,
    -0.9390815388942412,
    -1.1462779473024278,
    -1.130393343854788,
    -1.1155182352397528,
    -0.8903269664187031,
    -1.023337648925999,
    -0.86929004756323,
    -1.0955860454380946,
    -1.015301858651395,
    -0.9683892528365537,
    -0.9750107086966757,
    -0.9918877315839472,
    -1.1395113302964213,
    -0.9072369488593398,
    -0.951028855301499,
    -1.1784587440459142,
    -1.101311584880831,
    -0.9587403264585735,
    -0.7829364410976746,
    -1.0221540405199723,
    -0.8361271220479903,
    -0.9719452306085375,
    -0.7232377207775067,
    -0.8618007016983167,
    -1.0182170647811453,
    -0.9618666313115621,
    -0.9552654853996906,
    -1.050100167333305,
    -0.9575188572239074,
    -1.0002464886225553,
    -0.8965928803216253,
    -0.8919808772898961,
    -1.1036317035378553,
    -0.9707172228345357,
    -0.8729316568017386,
    -0.7867499877187647,
    -0.8984629815631385,
    -0.9527419867437745,
    -0.9752744941390303,
    -0.8419864711126714,
    -0.9763504438454927,
    -1.018087263518235,
    -1.0658790804013818,
    -0.9683331188532429,
    -0.8875157202951682,
    -1.0374736600198442,
    -1.111271047154716,
    -0.9029489835932278,
    -1.0108151466225264,
    -0.9711745967545107,
    -0.8339283346569286,
    -1.014232084933213,
    -0.8023505354935487,
    -0.8330594690156758,
    -1.038802560138669,
    -1.1681608924965974,
    -1.0528472278645935,
    -0.8822347664902064,
    -0.8808222103573167,
    -1.0851919209691725,
    -1.027366987495169,
    -1.0695461978638263,
    -0.9068627181219944,
    -0.8968729844050075,
    -0.880999397684065,
    -0.7861682446834788,
    -0.9685476880414624,
    -0.8758334635283033,
    -0.8771830722796998,
    -0.991978414088151,
    -0.8764932671448482
  ],
type: 'scatter3d',
mode: 'markers',
marker: {color: 'green', size: 4, opacity: 0.5},
showlegend: false
},
{
  x: [-1.5, 1.5, 1.5, -1.5],    // axis-aligned rectangle in x1
  y: [-1.5, -1.5, 1.5, 1.5],    // axis-aligned rectangle in x2
  z: [0, 0, 0, 0],      // all vertices on x3 = 0 -> plane orthogonal to z axis
  // two triangles covering the quad: (0,1,2) and (0,2,3)
  i: [0, 0],
  j: [1, 2],
  k: [2, 3],
type: 'mesh3d',
name: 'Hyperplane',
color: 'blue',
opacity: 0.35,
showlegend: true,
visible: 'legendonly'
}]"
:layout="{
   scene: {camera: {eye: {x: 0.0, y: 0.0, z: 2.5}},
            xaxis: {title: 'x<sub>1</sub>', range: [-1.6, 1.6]},
            yaxis: {title: 'x<sub>2</sub>', range: [-1.6, 1.6]},
            zaxis: {title: 'x<sub>3</sub>', range: [-1.6, 1.6]}},
   margin: {l: 20, r:20, b:20, t:1, pad: 5},
}"
:config="{displayModeBar: false}"
:options="{}"/>
</div>

---

# Support Vector Machines (SVM)
<br>

* We can further extend SVC by adding non-linear terms  $X_i^d, X_i X_j, ...$
	* However, optimization requires significant computing resources
* Instead, we can use a **kernel trick**
* Consider a **linear kernel** for $u, v \in \R^p$:
$
~K(u, v) = \langle u, v \rangle = \sum\limits_{j=1}^p u_j v_j = u \cdot v = u^{\prime}v
$
* It turns out that SVC optimization can be rewritten via
$
f(x) = \sum\limits_{i=1}^n \alpha_i K(x, x_i)
$
	* To estimate $\alpha_{1:n}$ and $\beta_0$ we need $\frac{n(n-1)}{2}$ **inner products**... , however...
	* $\alpha \neq 0$ only for the support vectors
		* So, estimation simplifies to
$
f(x) = \sum\limits_{i \in S}^n \alpha_i K(x, x_i)
$,

where $S$ is a set of support vectors (determined during training)

---

# Kernels in Machine Learning

* Many linear parametric models can be re-cast into an equivalent ‘dual representation’ in which the predictions are also based on linear combinations of a kernel function evaluated at the training data points
	* For models which are based on a fixed nonlinear feature space mapping $\phi(x)$, the kernel function is given by the relation<br> $k(\bm{x, x}^\prime) = \phi(\bm{x})^T \phi(\bm{x}^\prime)$
		* The kernel is a symmetric function of its arguments:<br> $k(\bm{x, x}^\prime) = k(\bm{x}^\prime, \bm{x})$
	* The simplest example of a kernel function is **linear kernel**:<br> $\phi(x) = x$, in which case $k(\bm{x, x}^\prime) = \bm{x}^T \bm{x}^\prime$

---
zoom: 0.93
--- 

# SVM Kernels

* The nonlinear classifier works by considering a nonlinear transformation $\phi(x)$ from the original space into a higher dimensional space
	* This nonlinear transformation can increase the linear separability of the classes
	* In practice, all dot products are replaced by the $K(x, x_i)$ kernel

<br>
<center>
<figure>
	<img src="/kernel.png" style="width: 580px !important">
	<figcaption style="color:#b3b3b3ff; font-size: 11px">Image source:
	  <a href="https://ipython-books.github.io/85-using-support-vector-machines-for-classification-tasks/">https://ipython-books.github.io/85-using-support-vector-machines-for-classification-tasks/</a>
	</figcaption>
</figure>
</center>
---

# We can also add non-linearity via
<br>
<v-clicks>

* **Polynomial kernel** of degree $d$:
$$
K(u,v) = (1 + \sum\limits_{j=1}^p u_j v_j)^d
$$

* **Radial (basis) kernel** of degree $d$:
$$
K(u,v) = \mathrm{exp}\Big[-\gamma \sum\limits_{j=1}^p (u_j - v_j)^2 \Big] = \mathrm{exp}\Big[-\gamma ||u_j - v_j||_2^2 \Big] ~~~\mathrm{\textcolor{black}{for}} ~~~\gamma \gt 0
$$

* **Neural network kernel**:
$$
K(u,v) = \mathrm{tanh}\Big[a \langle u, v \rangle + r \Big]
$$
</v-clicks>
---

# Radial Basis Kernel, $\mathrm{exp}\big[-\gamma ||u_j - v_j||_2^2 \big]$

<div class="grid grid-cols-[4fr,3fr]">
<div>

* It is essentially an unscaled Gaussian PDF
* Large $u - v$ implies near zero exponent
* So, in $f(x) = \beta_0 + \sum\limits_{i \in S}^n \alpha_i K(x, x_i)$
	* $\alpha = 0$ for non-support vectors, or
	* $K(x, x_i) \approx 0$ for distant observations $x_i$

</div>
<div>
<figure>
	<img src="/Normal_Distribution_PDF.svg" style="width: 250px !important">
	<figcaption style="color:#b3b3b3ff; font-size: 11px">Image source:
	  <a href="https://en.wikipedia.org/wiki/Normal_distribution">https://en.wikipedia.org/wiki/Normal_distribution</a>
	</figcaption>
</figure>
</div>
</div>

* Hence, only neighboring support vectors participate in forming a decision boundary
<div class="grid grid-cols-[3fr,3fr]">
<div>
	<br>
</div>
<div>
<figure>
	<img src="/ISLRv2_figure_9.9.png" style="width: 330px !important">
	<figcaption style="color:#b3b3b3ff; font-size: 11px">Image source:
	  <a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf#page=390">ISLR Fig. 9.9</a>
	</figcaption>
</figure>
</div>
</div>

---

# Ex. SVM vs LDA on Heart Disease Data
<br>

* Both SVM & LDA compute scores of the form<br>
$\hat{f}(X) = \hat{\beta}_0 + \hat{\beta}_1 X_1 + \hat{\beta}_2 X_2 + ... + \hat{\beta}_p X_p$
<br>

<center>
<figure>
	<br>
	<br>
	<img src="/ISLP_figure_9.11.png" style="width: 520px !important">
	<figcaption style="color:#b3b3b3ff; font-size: 11px">Image source:
	  <a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf#page=392">ISLP Fig. 9.11</a>
	</figcaption>
</figure>
</center>

---

# SVM is a Binary Classifier

* ... but can be extended to multiclass.
* Consider $K > 2$ classes and a test observation $x^{*}$
* **One-versus-one** (OVO) approach
	* Fit $\binom{K}{2}$ pairwise SVMs 
	* Assign $x^{*}$ to the most frequently predicted class
	* Disadvantage: lots of models to fit and inference with
* **One-versus-all** (OVA) approach
	* Fit $K$ SVMs for one of $K$ classes versus all other $K - 1$ classes combined
	* Assign $x^{*}$ to the class with greatest $\beta_{0k} + \beta_{1k}^{\prime} x_1^{*} + ... + \beta_{pk}^{\prime} x_p^{*}$ value
		* Where $\beta_{ik}$ are fitted for each class $k = 1:K$
	* Disadvantage: even if we start with **balanced** $K$ classes, we will face **imbalanced** aggregated classes, which will require probability threshold tuning

---

# SVM vs Logistic Regression
<br>

* Another form for SVM is
$
~~\underset{\beta_{0:p}}{\mathrm{argmin}} \bigg\{ \sum\limits_{i=1}^n \underbrace{\mathrm{max}[0, 1 - y_i f(x_i)]}_{\text{\textcolor{grey}{Hinge loss}}} ~+ \underbrace{\lambda \sum\limits_{j=1}^p \beta_j^2}_{\text{\textcolor{grey}{Ridge penalty}}} \bigg\},
$
<br>

<div class="grid grid-cols-[4fr_3fr]">
<div>

where $\lambda \geq 0$ and correlates with the parameter $C$

* Hinge loss is similar to logistic regression loss
* Changing the loss function yields a regularized logistic regression
</div>
<div>
<figure>
	<br>
	<img src="/ISLRv2_figure_9.12.png" style="width: 280px !important">
	<figcaption style="color:#b3b3b3ff; font-size: 11px">Image source:
	  <a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf#page=395">ISLR Fig. 9.12</a>
	</figcaption>
</figure>
</div>
</div>

---

# SVM Playgrounds

* [http://macheads101.com/demos/svm-playground](http://macheads101.com/demos/svm-playground)

* [https://ml-playground.com](https://ml-playground.com)

* [https://mlplaygrounds.com/machine/learning/svm.html](https://mlplaygrounds.com/machine/learning/svm.html)

* [https://greitemann.dev/svm-demo](https://greitemann.dev/svm-demo)

<br>

* Examine also Perceptron playground:
	* [https://perceptrondemo.com](https://perceptrondemo.com)